{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "from model_toy import get_toy_ResNet\n",
    "\n",
    "root_logs = os.path.join('logs', 'custom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_full, y_train_full), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train_full, x_test = x_train_full/255., x_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val,  y_train, y_val  = train_test_split(x_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the toy ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  9216      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  128       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "res_block (Res_block)        multiple                  18688     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            multiple                  18432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch multiple                  256       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "res_block_1 (Res_block)      multiple                  74240     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            multiple                  73728     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch multiple                  512       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  650       \n",
      "=================================================================\n",
      "Total params: 205,002\n",
      "Trainable params: 204,170\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_toy_ResNet()\n",
    "model.build(x_train.shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs     = 10\n",
    "batch_size = 32\n",
    "loss_fn    = tf.keras.losses.sparse_categorical_crossentropy\n",
    "optimizer  = tf.keras.optimizers.RMSprop()\n",
    "acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 8s 7ms/step - loss: 1.9144 - sparse_categorical_accuracy: 0.2926 - val_loss: 1.7986 - val_sparse_categorical_accuracy: 0.3687\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 7s 6ms/step - loss: 1.4954 - sparse_categorical_accuracy: 0.4707 - val_loss: 1.5852 - val_sparse_categorical_accuracy: 0.4982\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 7s 6ms/step - loss: 1.3353 - sparse_categorical_accuracy: 0.5423 - val_loss: 1.3281 - val_sparse_categorical_accuracy: 0.5313\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 7s 6ms/step - loss: 1.2062 - sparse_categorical_accuracy: 0.5871 - val_loss: 1.3513 - val_sparse_categorical_accuracy: 0.5542\n",
      "Epoch 5/10\n",
      "1172/1172 [==============================] - 7s 6ms/step - loss: 1.1239 - sparse_categorical_accuracy: 0.6220 - val_loss: 1.0842 - val_sparse_categorical_accuracy: 0.6418\n",
      "Epoch 6/10\n",
      "1172/1172 [==============================] - 7s 6ms/step - loss: 1.0638 - sparse_categorical_accuracy: 0.6470 - val_loss: 1.2635 - val_sparse_categorical_accuracy: 0.5952\n",
      "Epoch 7/10\n",
      "1172/1172 [==============================] - 7s 6ms/step - loss: 1.0229 - sparse_categorical_accuracy: 0.6653 - val_loss: 0.9261 - val_sparse_categorical_accuracy: 0.6933\n",
      "Epoch 8/10\n",
      "1172/1172 [==============================] - 7s 6ms/step - loss: 0.9743 - sparse_categorical_accuracy: 0.6838 - val_loss: 0.9126 - val_sparse_categorical_accuracy: 0.6944\n",
      "Epoch 9/10\n",
      "1172/1172 [==============================] - 7s 6ms/step - loss: 0.9311 - sparse_categorical_accuracy: 0.6977 - val_loss: 1.2979 - val_sparse_categorical_accuracy: 0.6119\n",
      "Epoch 10/10\n",
      "1172/1172 [==============================] - 7s 6ms/step - loss: 0.8972 - sparse_categorical_accuracy: 0.7097 - val_loss: 0.9703 - val_sparse_categorical_accuracy: 0.7075\n",
      "10 epochs in 78.30s\n"
     ]
    }
   ],
   "source": [
    "model = get_toy_ResNet()\n",
    "\n",
    "model.compile(loss=loss_fn, optimizer=optimizer, metrics=[acc_metric])\n",
    "start = time()\n",
    "history = model.fit(x=x_train, y=y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs, verbose=1,\n",
    "                    validation_data=(x_val, y_val))\n",
    "stop = time()\n",
    "print(\"%d epochs in %.2fs\"%(epochs, stop-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size):\n",
    "    idx = np.random.randint(low=0, high=len(x_train), size=batch_size)\n",
    "    return x_train[idx], y_train[idx]\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, loss_fn, optimizer, x_batch, y_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward\n",
    "        y_pred   = model(x_batch, training=True)\n",
    "        out_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "        tot_loss = tf.add_n([out_loss] + model.losses)\n",
    "    # Backward    \n",
    "    gradients = tape.gradient(tot_loss, model.trainable_variables)\n",
    "    # Update\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return y_pred, tot_loss\n",
    "\n",
    "def predict(model, loss_fn, x_batch, y_batch):\n",
    "    y_pred   = model(x_batch, training=False)\n",
    "    out_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "    tot_loss = tf.add_n([out_loss] + model.losses)\n",
    "    return y_pred, tot_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer conv2d_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 0/10: 8.7333s\tTrain: accuracy: 0.314 - last loss: 1.415\tValidation: accuracy 0.458 - mean loss 1.568\n",
      "Epoch 1/10: 7.1448s\tTrain: accuracy: 0.482 - last loss: 1.008\tValidation: accuracy 0.570 - mean loss 1.228\n",
      "Epoch 2/10: 7.1412s\tTrain: accuracy: 0.556 - last loss: 1.869\tValidation: accuracy 0.562 - mean loss 1.374\n",
      "Epoch 3/10: 7.1372s\tTrain: accuracy: 0.601 - last loss: 0.860\tValidation: accuracy 0.655 - mean loss 1.053\n",
      "Epoch 4/10: 7.1305s\tTrain: accuracy: 0.635 - last loss: 1.008\tValidation: accuracy 0.624 - mean loss 1.240\n",
      "Epoch 5/10: 7.1365s\tTrain: accuracy: 0.654 - last loss: 1.274\tValidation: accuracy 0.623 - mean loss 1.144\n",
      "Epoch 6/10: 7.1344s\tTrain: accuracy: 0.677 - last loss: 1.711\tValidation: accuracy 0.638 - mean loss 1.139\n",
      "Epoch 7/10: 7.1408s\tTrain: accuracy: 0.698 - last loss: 1.091\tValidation: accuracy 0.683 - mean loss 1.090\n",
      "Epoch 8/10: 7.1261s\tTrain: accuracy: 0.713 - last loss: 1.941\tValidation: accuracy 0.663 - mean loss 1.226\n",
      "Epoch 9/10: 7.1431s\tTrain: accuracy: 0.724 - last loss: 0.923\tValidation: accuracy 0.736 - mean loss 0.888\n",
      "10 epochs in 131.11s\n"
     ]
    }
   ],
   "source": [
    "model = get_toy_ResNet()\n",
    "# Metrics\n",
    "acc_metric.reset_states()\n",
    "loss_metric = tf.keras.metrics.Mean()\n",
    "\n",
    "start_t = time()\n",
    "for epoch in range(epochs):\n",
    "    start = time()\n",
    "    # Train\n",
    "    for i in range(0,len(x_train),batch_size):\n",
    "        x_batch, y_batch = get_batch(batch_size)\n",
    "        y_pred, loss     = train_step(model, loss_fn, optimizer, x_batch, y_batch)\n",
    "        acc_metric.update_state(y_batch, y_pred)    \n",
    "    train_acc = acc_metric.result()\n",
    "    acc_metric.reset_states()\n",
    "    stop = time()\n",
    "    \n",
    "    # Validate\n",
    "    for i in range(0,len(x_val),batch_size):\n",
    "        x_batch, y_batch = x_val[i:i+batch_size], y_val[i:i+batch_size]\n",
    "        y_pred, loss     = predict(model, loss_fn, x_batch, y_batch)\n",
    "        acc_metric.update_state(y_batch, y_pred)\n",
    "        loss_metric.update_state(loss)\n",
    "    val_acc  = acc_metric.result()\n",
    "    loss_acc = loss_metric.result()\n",
    "    acc_metric.reset_states()    \n",
    "    loss_metric.reset_states()    \n",
    "    print(\"Epoch %d/%d: %.4fs\\tTrain: accuracy: %.3f - last loss: %.3f\\tValidation: accuracy %.3f - mean loss %.3f\"%\n",
    "          (epoch, epochs, stop - start, train_acc, loss, val_acc, loss_acc))\n",
    "stop_t = time()    \n",
    "print(\"%d epochs in %.2fs\"%(epochs, stop_t-start_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 DL",
   "language": "python",
   "name": "dl-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
