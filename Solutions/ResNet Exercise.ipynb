{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet Exercise:\n",
    "\n",
    "In the file model_ResNetv2.py you can find an accurate implementation of the ResNet v2 (from here). Create a tf.Dataset containing CIFAR10, apply to it some basic image preprocessing (avoid rotation!) and train a ResNet56_v2 model on it for at least 30 epochs. Distribute the training over multiple GPUs (try at least with 2) and test different batch sizes. How does the time per epoch change? What about the validation accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from day2.model_ResNetv2 import resnet_v2 as resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=128\n",
    "epochs=30 \n",
    "height=32\n",
    "width=32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Preprocessing & DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x, y), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(x, y):\n",
    "    x = tf.image.resize_with_crop_or_pad(\n",
    "        x, height + 8, width + 8)\n",
    "    x = tf.image.random_crop(x, [height, width, 3])\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    return x, y\n",
    "\n",
    "def preprocess(x, y):\n",
    "    x = tf.image.per_image_standardization(x)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (train_dataset\n",
    "                 .map(augmentation)\n",
    "                 .shuffle(buffer_size=50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, y):\n",
    "    x = tf.image.per_image_standardization(x)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (train_dataset\n",
    "                 .map(augmentation)\n",
    "                 .shuffle(buffer_size=50000)\n",
    "                 .map(normalize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (train_dataset.map(augmentation)\n",
    "                 .map(normalize)\n",
    "                 .shuffle(50000)\n",
    "                 .batch(128, drop_remainder=True))\n",
    "\n",
    "test_dataset = test_dataset.map(preprocess).batch(128*2, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image dimensions.\n",
    "input_shape = x.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = resnet(input_shape=input_shape , depth=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "with mirrored_strategy.scope():\n",
    "    #model = resnet.resnet56(classes=10)\n",
    "    model = resnet(input_shape=input_shape , depth=56)\n",
    "    model.compile(\n",
    "            optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_SCHEDULE = [(0.1, 30), (0.01, 45)]\n",
    "\n",
    "def schedule(epoch):\n",
    "    initial_learning_rate = 0.1 * 128 / 128\n",
    "    learning_rate = initial_learning_rate\n",
    "    for mult, start_epoch in LR_SCHEDULE:\n",
    "        if epoch >= start_epoch:\n",
    "            learning_rate = initial_learning_rate * mult\n",
    "        else:\n",
    "            break\n",
    "    tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "    return learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "390/390 [==============================] - 24s 63ms/step - accuracy: 0.4026 - loss: 2.6115 - val_accuracy: 0.1694 - val_loss: 4.9742 - lr: 0.1000\n",
      "Epoch 2/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.4832 - loss: 2.2907 - val_accuracy: 0.3947 - val_loss: 2.6633 - lr: 0.1000\n",
      "Epoch 3/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.5315 - loss: 2.0660 - val_accuracy: 0.4272 - val_loss: 2.4211 - lr: 0.1000\n",
      "Epoch 4/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.5684 - loss: 1.8869 - val_accuracy: 0.3982 - val_loss: 2.5601 - lr: 0.1000\n",
      "Epoch 5/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.5987 - loss: 1.7284 - val_accuracy: 0.3976 - val_loss: 2.5777 - lr: 0.1000\n",
      "Epoch 6/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.6234 - loss: 1.6008 - val_accuracy: 0.5130 - val_loss: 1.9399 - lr: 0.1000\n",
      "Epoch 7/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.6427 - loss: 1.5018 - val_accuracy: 0.3907 - val_loss: 2.7548 - lr: 0.1000\n",
      "Epoch 8/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.6553 - loss: 1.4283 - val_accuracy: 0.4340 - val_loss: 2.4525 - lr: 0.1000\n",
      "Epoch 9/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.6664 - loss: 1.3626 - val_accuracy: 0.5477 - val_loss: 1.8028 - lr: 0.1000\n",
      "Epoch 10/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.6762 - loss: 1.3070 - val_accuracy: 0.6268 - val_loss: 1.4920 - lr: 0.1000\n",
      "Epoch 11/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.6866 - loss: 1.2512 - val_accuracy: 0.6189 - val_loss: 1.5225 - lr: 0.1000\n",
      "Epoch 12/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.6962 - loss: 1.2120 - val_accuracy: 0.6605 - val_loss: 1.2949 - lr: 0.1000\n",
      "Epoch 13/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.6991 - loss: 1.1860 - val_accuracy: 0.6894 - val_loss: 1.2536 - lr: 0.1000\n",
      "Epoch 14/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.7055 - loss: 1.1525 - val_accuracy: 0.5680 - val_loss: 1.5708 - lr: 0.1000\n",
      "Epoch 15/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.7121 - loss: 1.1257 - val_accuracy: 0.6132 - val_loss: 1.4257 - lr: 0.1000\n",
      "Epoch 16/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.7193 - loss: 1.1036 - val_accuracy: 0.6148 - val_loss: 1.5940 - lr: 0.1000\n",
      "Epoch 17/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.7226 - loss: 1.0803 - val_accuracy: 0.6183 - val_loss: 1.3920 - lr: 0.1000\n",
      "Epoch 18/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.7208 - loss: 1.0718 - val_accuracy: 0.5711 - val_loss: 1.6629 - lr: 0.1000\n",
      "Epoch 19/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.7279 - loss: 1.0519 - val_accuracy: 0.7117 - val_loss: 1.1512 - lr: 0.1000\n",
      "Epoch 20/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.7337 - loss: 1.0353 - val_accuracy: 0.5841 - val_loss: 1.6372 - lr: 0.1000\n",
      "Epoch 21/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.7357 - loss: 1.0240 - val_accuracy: 0.5733 - val_loss: 1.5738 - lr: 0.1000\n",
      "Epoch 22/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.7375 - loss: 1.0152 - val_accuracy: 0.6247 - val_loss: 1.4704 - lr: 0.1000\n",
      "Epoch 23/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.7433 - loss: 1.0038 - val_accuracy: 0.6338 - val_loss: 1.5528 - lr: 0.1000\n",
      "Epoch 24/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.7444 - loss: 1.0014 - val_accuracy: 0.6737 - val_loss: 1.3155 - lr: 0.1000\n",
      "Epoch 25/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.7457 - loss: 0.9950 - val_accuracy: 0.6404 - val_loss: 1.3846 - lr: 0.1000\n",
      "Epoch 26/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.7488 - loss: 0.9829 - val_accuracy: 0.5524 - val_loss: 1.7751 - lr: 0.1000\n",
      "Epoch 27/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.7486 - loss: 0.9790 - val_accuracy: 0.7045 - val_loss: 1.1095 - lr: 0.1000\n",
      "Epoch 28/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.7532 - loss: 0.9689 - val_accuracy: 0.6874 - val_loss: 1.2151 - lr: 0.1000\n",
      "Epoch 29/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.7528 - loss: 0.9689 - val_accuracy: 0.6084 - val_loss: 1.4720 - lr: 0.1000\n",
      "Epoch 30/30\n",
      "390/390 [==============================] - 20s 52ms/step - accuracy: 0.7564 - loss: 0.9644 - val_accuracy: 0.6509 - val_loss: 1.3283 - lr: 0.1000\n",
      "39/39 [==============================] - 1s 21ms/step - accuracy: 0.6509 - loss: 1.3283\n"
     ]
    }
   ],
   "source": [
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "file_writer.set_as_default()\n",
    "tensorboard_callback = TensorBoard(\n",
    "  log_dir=log_dir,\n",
    "  update_freq='batch',\n",
    "  histogram_freq=1)\n",
    "\n",
    "lr_schedule_callback = LearningRateScheduler(schedule)\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "          epochs=30,\n",
    "          validation_data=test_dataset,\n",
    "          validation_freq=1,\n",
    "          callbacks=[tensorboard_callback, lr_schedule_callback])\n",
    "history = model.evaluate(test_dataset)\n",
    "\n",
    "history = model.save('model_resnet_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 21ms/step - accuracy: 0.6509 - loss: 1.3283\n"
     ]
    }
   ],
   "source": [
    "history = model.evaluate(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 DL",
   "language": "python",
   "name": "dl-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
